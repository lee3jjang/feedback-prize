{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nfrom ast import literal_eval\nfrom transformers import *\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:59:45.600994Z","iopub.execute_input":"2022-01-10T14:59:45.601275Z","iopub.status.idle":"2022-01-10T14:59:55.587363Z","shell.execute_reply.started":"2022-01-10T14:59:45.601192Z","shell.execute_reply":"2022-01-10T14:59:55.586541Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# 환경설정\n## 기타설정\nos.makedirs('model', exist_ok=True)\nos.makedirs('tokens', exist_ok=True)\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nwarnings.filterwarnings('ignore')\n\n## 환경변수\nVER = 0.1\nMODEL_NAME = 'google/bigbird-roberta-base'\nCONFIG = {\n    'model_name': MODEL_NAME,\n    'max_length': 1024,\n    'train_batch_size': 4,\n    'valid_batch_size': 4,\n    'epochs': 5,\n    'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n    'max_grad_norm': 10,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n}\nCOMPUTE_VAL_SCORE = True\n\nOUTPUT_LABELS = [\n    'O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position',\n    'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n    'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence',\n    'B-Concluding Statement', 'I-Concluding Statement'\n]\nLABELS_TO_IDS = {v: k for k, v in enumerate(OUTPUT_LABELS)}\nIDS_TO_LABELS = {k: v for k, v in enumerate(OUTPUT_LABELS)}","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:59:55.589498Z","iopub.execute_input":"2022-01-10T14:59:55.589778Z","iopub.status.idle":"2022-01-10T14:59:55.881443Z","shell.execute_reply.started":"2022-01-10T14:59:55.589741Z","shell.execute_reply":"2022-01-10T14:59:55.880752Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## 모델 설정\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True, cache_dir='cache')\ntokenizer.save_pretrained('model')\n\nconfig_model = AutoConfig.from_pretrained(MODEL_NAME)\nconfig_model.num_labels = 15\nconfig_model.save_pretrained('model')\n\nbackbone = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config_model)\nbackbone.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:59:55.882705Z","iopub.execute_input":"2022-01-10T14:59:55.882932Z","iopub.status.idle":"2022-01-10T15:00:18.876274Z","shell.execute_reply.started":"2022-01-10T14:59:55.882900Z","shell.execute_reply":"2022-01-10T15:00:18.875512Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## train.csv\ntrain_df = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\n\n## train\ntrain_ids, train_texts = [], []\nfor f in tqdm(os.listdir('/kaggle/input/feedback-prize-2021/train')):\n    train_ids.append(f.replace('.txt', ''))\n    train_texts.append(open(f'/kaggle/input/feedback-prize-2021/train/{f}', 'r', encoding='utf8').read())\ntrain_text_df = pd.DataFrame({'id': train_ids, 'text': train_texts})\n\n## test\ntest_ids, test_texts = [], []\nfor f in tqdm(os.listdir('/kaggle/input/feedback-prize-2021/test')):\n    test_ids.append(f.replace('.txt', ''))\n    test_texts.append(open(f'/kaggle/input/feedback-prize-2021/test/{f}', 'r', encoding='utf8').read())\ntest_text_df = pd.DataFrame({'id': test_ids, 'text': test_texts})","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:00:18.878353Z","iopub.execute_input":"2022-01-10T15:00:18.878600Z","iopub.status.idle":"2022-01-10T15:01:07.141362Z","shell.execute_reply.started":"2022-01-10T15:00:18.878567Z","shell.execute_reply":"2022-01-10T15:01:07.140654Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 데이터 가공\nif 'train_NER.csv' not in os.listdir('tokens'):\n  all_entities = []\n  for i, row in train_text_df.iterrows():\n      if i%100 == 0: print(i, '', end='')\n      total = len(row['text'].split())\n      id = row['id']\n      entities = ['O']*total\n      for _, discource in train_df.query(\"id == @id\").iterrows():\n          disc_type = discource['discourse_type']\n          list_ix = [int(x) for x in discource['predictionstring'].split(' ')]\n          entities[list_ix[0]] = f'B-{disc_type}'\n          for j in list_ix[1:]:\n              entities[j] = f'I-{disc_type}'\n      all_entities.append(entities)\n  train_text_df['entities'] = all_entities\n  train_text_df.to_csv('tokens/train_NER.csv', index=False)\n\ntrain_text_df = pd.read_csv('tokens/train_NER.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:01:07.142872Z","iopub.execute_input":"2022-01-10T15:01:07.143281Z","iopub.status.idle":"2022-01-10T15:03:13.563465Z","shell.execute_reply.started":"2022-01-10T15:01:07.143244Z","shell.execute_reply":"2022-01-10T15:03:13.562605Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 데이터셋 클래스 정의\nclass CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length, get_wids):\n        self.len = len(data)\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.get_wids = get_wids\n\n    def __getitem__(self, index):\n        text = self.data.text[index]\n        word_labels = eval(self.data.entities[index]) if not self.get_wids else None\n\n        encoding = self.tokenizer(\n            text.split(),\n            is_split_into_words = True,\n            padding = 'max_length',\n            truncation = True,\n            max_length = self.max_length\n        )\n        word_ids = encoding.word_ids()\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n\n        if not self.get_wids:\n            label_ids = []\n            for word_idx in word_ids:\n                label_ids.append(LABELS_TO_IDS[word_labels[word_idx]] if word_idx is not None else -100)\n            item['labels'] = torch.as_tensor(label_ids)\n        else:\n            item['wids'] = torch.as_tensor([w if w is not None else -1 for w in word_ids])\n\n        return item\n                \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:03:13.565913Z","iopub.execute_input":"2022-01-10T15:03:13.566463Z","iopub.status.idle":"2022-01-10T15:03:13.577985Z","shell.execute_reply.started":"2022-01-10T15:03:13.566423Z","shell.execute_reply":"2022-01-10T15:03:13.577091Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 데이터 로더 생성\nall_idx = train_df.id.unique()\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(all_idx)), int(0.9*len(all_idx)), replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(all_idx)), train_idx)\nnp.random.seed(None)\n\ntokenizer = AutoTokenizer.from_pretrained('model')\n\ntrain_dataset = train_text_df.query('id in @all_idx[@train_idx]')[['text', 'entities']].reset_index(drop=True)\nvalid_dataset = train_text_df.query('id in @all_idx[@valid_idx]').reset_index(drop=True)\ntest_dataset = test_text_df.copy()\n\ntraining_set = CustomDataset(train_dataset, tokenizer, CONFIG['max_length'], False)\nvalidating_set = CustomDataset(valid_dataset, tokenizer, CONFIG['max_length'], True)\ntesting_set = CustomDataset(test_dataset, tokenizer, CONFIG['max_length'], True)\n\ntrain_params = {\n    'batch_size': CONFIG['train_batch_size'],\n    'shuffle': True,\n    'num_workers': 4,\n    'pin_memory': True\n}\n\nvalid_params = {\n    'batch_size': CONFIG['valid_batch_size'],\n    'shuffle': False,\n    'num_workers': 4,\n    'pin_memory': True\n}\n\ntraining_loader = DataLoader(training_set, **train_params)\nvalidating_loader = DataLoader(validating_set, **valid_params)\ntesting_loader = DataLoader(testing_set, **valid_params)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:03:13.579659Z","iopub.execute_input":"2022-01-10T15:03:13.579940Z","iopub.status.idle":"2022-01-10T15:03:14.218299Z","shell.execute_reply.started":"2022-01-10T15:03:13.579905Z","shell.execute_reply":"2022-01-10T15:03:14.217487Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 모델 설정\nconfig_model = AutoConfig.from_pretrained('model/config.json')\nmodel = AutoModelForTokenClassification.from_pretrained('model/pytorch_model.bin', config=config_model)\nmodel.to(CONFIG['device'])\noptimizer = torch.optim.Adam(params=model.parameters(), lr=CONFIG['learning_rates'][0])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:03:14.219816Z","iopub.execute_input":"2022-01-10T15:03:14.220106Z","iopub.status.idle":"2022-01-10T15:03:20.322137Z","shell.execute_reply.started":"2022-01-10T15:03:14.220068Z","shell.execute_reply":"2022-01-10T15:03:20.321341Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# 모델 학습\nfor epoch in range(CONFIG['epochs']):\n\n    for g in optimizer.param_groups:\n        g['lr'] = CONFIG['learning_rates'][epoch]\n\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    model.train()\n    for idx, batch in enumerate(training_loader):\n        ids = batch['input_ids'].to(CONFIG['device'], dtype=torch.long)\n        mask = batch['attention_mask'].to(CONFIG['device'], dtype=torch.long)\n        labels = batch['labels'].to(CONFIG['device'], dtype=torch.long)\n        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict=False)\n        tr_loss += loss.item()\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n\n        if idx % 200==0:\n            loss_step = tr_loss/nb_tr_steps\n            print(f\"Training loss after {idx:04d} training steps: {loss_step}\")\n\n        flattened_targets = labels.view(-1)\n        active_logits = tr_logits.view(-1, model.num_labels)\n        flattened_predictions = torch.argmax(active_logits, axis=1)\n        active_accuracy = labels.view(-1) != -100\n        labels = torch.masked_select(flattened_targets, active_accuracy)\n        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n        tr_accuracy += accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=CONFIG['max_grad_norm'])\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_accuracy = tr_accuracy / nb_tr_steps\n    print(f\"Training loss epoch: {epoch_loss}\")\n    print(f\"Training accuracy epoch: {tr_accuracy}\")\n\ntorch.save(model.state_dict(), f'bigbird_v{VER}.pt')\n# model.load_state_dict(torch.load(f'bigbird_v{VER}.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:04:16.648416Z","iopub.execute_input":"2022-01-10T15:04:16.648698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(batch):\n    ids = batch['input_ids'].to(CONFIG['device'])\n    mask = batch['attention_mask'].to(CONFIG['device'])\n    outputs = model(input_ids=ids, attention_mask=mask, return_dict=False)\n    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy()\n\n    predictions = []\n    for k, text_preds in enumerate(all_preds):\n        token_preds = [IDS_TO_LABELS[i] for i in text_preds]\n\n        prediction = []\n        word_ids = batch['wids'][k].numpy()\n        previous_word_idx = -1\n        for idx, word_idx in enumerate(word_ids):\n          if word_idx == -1:\n            pass\n          elif word_idx != previous_word_idx:\n            prediction.append(token_preds[idx])\n            previous_word_idx = word_idx\n        predictions.append(prediction)\n\n    return predictions  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(df, loader):\n    model.eval()\n\n    y_pred2 = []\n    for batch in loader:\n        labels = inference(batch)\n        y_pred2.extend(labels)\n\n    final_preds2 = []\n    for i in range(len(df)):\n        idx = df.id.values[i]\n        pred = y_pred2[i]\n        j = 0\n        while j < len(pred):\n            cls = pred[j]\n            if cls == 'O':\n              j += 1\n            else:\n              cls = cls.replace('B', 'I')\n            end = j + 1\n            while end < len(pred) and pred[end] == cls:\n                end += 1\n            if cls != 'O' and cls != '' and end - j > 7:  \n                final_preds2.append((idx, cls.replace('I-', ''), ' '.join(map(str, list(range(j, end))))))\n            j = end\n    oof = pd.DataFrame(final_preds2)\n    oof.columns = ['id', 'class', 'predictionstring']\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return oof","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_overlap(row):\n    set_pred = set(row['predictionstring_pred'].split(' '))\n    set_gt = set(row['predictionstring_gt'].split(' '))\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    len_inter = len(set_pred.intersection(set_gt))\n    overlap_1 = len_inter/len_gt\n    overlap_2 = len_inter/len_pred\n    return [overlap_1, overlap_2]\n\ndef score_feedback_comp(pred_df, gt_df):\n    gt_df = gt_df[['id', 'discourse_type', 'predictionstring']].rename(columns={'discourse_type': 'class'}).reset_index(drop=True).rename_axis('pred_id').reset_index()\n    pred_df = pred_df.reset_index(drop=True).rename_axis('gt_id').reset_index()\n    joined_df = pred_df.merge(gt_df, on =['id', 'class'], how='outer', suffixes=('_pred', '_gt'))\n\n    joined_df = joined_df.assign(\n        predictionstring_pred = lambda x: x['predictionstring_pred'].fillna(' '),\n        predictionstring_gt = lambda x: x['predictionstring_gt'].fillna(' '),\n        overlaps = lambda x: x.apply(calc_overlap, axis=1),\n        overlap1 = lambda x: x['overlaps'].apply(lambda x: eval(str(x))[0]),\n        overlap2 = lambda x: x['overlaps'].apply(lambda x: eval(str(x))[1]),\n        potential_TP = lambda x: (x['overlap1'] >= 0.5) & (x['overlap2'] >= 0.5),\n        max_overlap = lambda x: x[['overlap1', 'overlap2']].max(axis=1),\n    )\n\n    tp_pred_ids = (joined_df\n      .query('potential_TP')\n      .sort_values(by='max_overlap', ascending=False)\n      .groupby(['id', 'predictionstring_gt']).first()['pred_id'].values\n    )\n    fp_pred_ids = [p for p in joined_df['pred_id'].unique() if p not in tp_pred_ids]\n    matched_gt_ids = joined_df.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined_df['gt_id'].unique() if c not in matched_gt_ids]\n\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = train_df.query('id in @all_idx[@valid_idx]')\noof = get_predictions(valid_dataset, validating_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nc = CLASSES[0]\nfor c in CLASSES:\n    gt_df = valid.loc[lambda x: x['discourse_type'] == c].copy()\n    pred_df = oof.loc[lambda x: x['class'] == c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c, f1)\n    f1s.append(f1)\nprint('='*30)\nprint('Overall', np.mean(f1s))\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = get_predictions(test_dataset, testing_loader)\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}